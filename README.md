# Hardware Accelerators Course

##  Course Information
- **Course Name:** Hardware Accelerators Course
- **Department:** Faculty of Engineering and Computer Science  
- **University:** Shahid Beheshti University  
---

##  introduction



This course provides a structured treatment of the key principles and techniques for enabling efficient processing of deep neural networks (DNNs). DNNs are currently widely used for many artificial intelligence (AI) applications, including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Therefore, techniques that enable efficient processing of deep neural networks to improve key metrics—such as energy-efficiency, throughput, and latency—without sacrificing accuracy or increasing hardware costs are critical to enabling the wide deployment of DNNs in AI systems.

---


 HW : Implementing a Neural Network for CIFAR-10 Classification [LINK](https://github.com/matinfirooz/Implementing-a-Neural-Network-for-CIFAR-10-Classification.git)
 
 HW : Convolution Operation Using CUDA [LINK](https://github.com/matinfirooz/Convolution-Operation-Using-CUDA.git)
 
 HW : Hardware-Accelerated MLP for Iris Dataset [LINK](https://github.com/matinfirooz/Hardware-Accelerated-MLP-for-Iris-Dataset.git).

 HW : LeNet-5-Quantization [LINK](https://github.com/matinfirooz/LeNet-5-Quantization.git).

 HW : LeNet-5 Pruning [LINK](https://github.com/matinfirooz/Lenet-5-Pruning.git).

 HW : Output Stationary TPU Systolic Array [LINK](https://github.com/matinfirooz/TPU-Systolic-Array.git).

 It will be published at the end of 2025!

---
 ## References
[1](“V. Sze, Y.-H. Chen, T.-J. Yang, and J. S. Emer, Efficient Processing of Deep Neural Networks. Cham: Springer International Publishing, 2020. doi: https://doi.org/10.1007/978-3-031-01766-7.”)  [LINK](https://link.springer.com/book/10.1007/978-3-031-01766-7).


 
