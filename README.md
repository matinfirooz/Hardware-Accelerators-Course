# Hardware Accelerators Course

## Course Information
- **Course Name:** Hardware Accelerators Course  
- **Department:** Faculty of Engineering and Computer Science  
- **University:** Shahid Beheshti University  

---

## Introduction

This course provides a structured treatment of the key principles and techniques for enabling efficient processing of deep neural networks (DNNs). DNNs are currently widely used in many artificial intelligence (AI) applications, including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, they come at the cost of high computational complexity. 

Therefore, this course explores techniques that improve key performance metricsâ€”such as energy efficiency, throughput, and latencyâ€”without sacrificing accuracy or increasing hardware costs. These techniques are critical for the widespread deployment of DNNs in real-world AI systems.

---

## Homework Assignments

- **Implementing a Neural Network for CIFAR-10 Classification:** [GitHub Link](https://github.com/matinfirooz/Implementing-a-Neural-Network-for-CIFAR-10-Classification.git)  
- **Convolution Operation Using CUDA:** [GitHub Link](https://github.com/matinfirooz/Convolution-Operation-Using-CUDA.git)  
- **Hardware-Accelerated MLP for Iris Dataset:** [GitHub Link](https://github.com/matinfirooz/Hardware-Accelerated-MLP-for-Iris-Dataset.git)  
- **LeNet-5 Quantization:** [GitHub Link](https://github.com/matinfirooz/LeNet-5-Quantization.git)  
- **LeNet-5 Pruning:** [GitHub Link](https://github.com/matinfirooz/Lenet-5-Pruning.git)  
- **Output Stationary TPU Systolic Array:** [GitHub Link](https://github.com/matinfirooz/TPU-Systolic-Array.git)  

ðŸ“Œ **Note:** Final project will be published at the end of 2025!

---

## References

1. *Efficient Processing of Deep Neural Networks*  
   **Authors:** Vivienne Sze, Yu-Hsin Chen, Tien-Ju Yang, and Joel S. Emer  
   [Springer Link](https://link.springer.com/book/10.1007/978-3-031-01766-7)
